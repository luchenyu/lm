{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os, sys, time\n",
    "import tensorflow as tf\n",
    "from model import file_input_fn, lm_model_fn, lr_range_test, train_and_evaluate\n",
    "from utils import data_utils_py3\n",
    "from os.path import expanduser\n",
    "HOME = expanduser(\"~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_vocab_file = HOME+\"/Data/Vocab/vocab_zh\"\n",
    "word_vocab_file = HOME+\"/Data/Vocab/word_vocab_zh\"\n",
    "char_embedding_files = HOME+\"/Data/Vocab/zh_char_300_nlpcc.txt\"\n",
    "data_dir = HOME+\"/Data/text_zh\"\n",
    "train_dir = 'estimator_zh_small'\n",
    "\n",
    "char_vocab = data_utils_py3.Vocab(\n",
    "    char_vocab_file,\n",
    "    embedding_files=char_embedding_files)\n",
    "char_vocab_size = char_vocab.size()\n",
    "\n",
    "params = {\n",
    "    'max_lr': 5e-5,\n",
    "    'num_steps': 200000,\n",
    "    'pct_start': 0.3,\n",
    "    'dropout': 0.1,\n",
    "    'wd': .0,\n",
    "    'char_vocab_size': char_vocab_size,\n",
    "    'char_vocab_dim': 300,\n",
    "    'char_vocab_emb': char_vocab.embedding_init,\n",
    "    'max_char_length': 8,\n",
    "    'layer_size': 256,\n",
    "    'num_layers': 3,\n",
    "    'data_spec': [{'type': 'seq', 'is_target': True, 'select_from': None}]\n",
    "}\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "num_pieces = 1\n",
    "max_lengths = [256]\n",
    "train_input_fn = lambda: file_input_fn(\n",
    "    char_vocab, os.path.join(data_dir, 'train'),\n",
    "    num_pieces, batch_size, max_lengths, True)\n",
    "eval_input_fn = lambda: file_input_fn(\n",
    "    char_vocab, os.path.join(data_dir, 'dev'),\n",
    "    num_pieces, batch_size, max_lengths, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = lr_range_test(lm_model_fn, train_input_fn, params, num_steps=10)\n",
    "[learning_rates, losses] = zip(*[(item['learning_rate'], item['loss']) for item in history])\n",
    "plt.semilogx(learning_rates,losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\n",
      "INFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_CPU:0\n",
      "INFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_GPU:0\n",
      "INFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_GPU:1\n",
      "INFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_GPU:2\n",
      "INFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_GPU:3\n",
      "INFO:tensorflow:Configured nccl all-reduce.\n",
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Using config: {'_task_type': 'worker', '_train_distribute': <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f2c38bdf668>, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2c38c5b2e8>, '_device_fn': None, '_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_protocol': None, '_num_worker_replicas': 1, '_is_chief': True, '_save_summary_steps': 100, '_experimental_distribute': None, '_log_step_count_steps': 1000, '_master': '', '_service': None, '_model_dir': 'estimator_zh_small', '_global_id_in_cluster': 0, '_distribute_coordinator_mode': None, '_eval_distribute': <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f2c38bdf668>, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_evaluation_master': '', '_tf_random_seed': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_task_id': 0}\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "total number of parameters is: 12299542\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:Create InsideHook.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create InsideHook.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create InsideHook.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create InsideHook.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "Before starting the session.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into estimator_zh_small/model.ckpt.\n",
      "INFO:tensorflow:Initialize strategy\n",
      "Session created.\n",
      "INFO:tensorflow:loss = 17.537878, step = 0\n",
      "INFO:tensorflow:global_step/sec: 2.07959\n",
      "INFO:tensorflow:loss = 11.101002, step = 1000 (480.871 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1184 into estimator_zh_small/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.18779\n",
      "INFO:tensorflow:loss = 10.712721, step = 2000 (457.080 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2501 into estimator_zh_small/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.18148\n",
      "INFO:tensorflow:loss = 10.373232, step = 3000 (458.406 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3816 into estimator_zh_small/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.18994\n",
      "INFO:tensorflow:loss = 10.250437, step = 4000 (456.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.21623\n",
      "INFO:tensorflow:loss = 10.154329, step = 5000 (451.215 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5134 into estimator_zh_small/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.18539\n",
      "INFO:tensorflow:loss = 10.0354, step = 6000 (457.583 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6449 into estimator_zh_small/model.ckpt.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:global_step/sec: 2.18219\n",
      "INFO:tensorflow:loss = 9.868438, step = 7000 (458.254 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7766 into estimator_zh_small/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.18904\n",
      "INFO:tensorflow:loss = 9.583206, step = 8000 (456.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.20746\n",
      "INFO:tensorflow:loss = 9.815489, step = 9000 (453.009 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9078 into estimator_zh_small/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into estimator_zh_small/model.ckpt.\n",
      "INFO:tensorflow:Finalize strategy.\n",
      "INFO:tensorflow:Loss for final step: 9.553037.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "total number of parameters is: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "total number of parameters is: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "total number of parameters is: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "total number of parameters is: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/metrics_impl.py:363: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-07T13:45:17Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from estimator_zh_small/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Initialize strategy\n",
      "INFO:tensorflow:Finalize strategy.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-07-13:45:38\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, loss = 9.433769\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: estimator_zh_small/model.ckpt-10000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "total number of parameters is: 12299542\n",
      "total number of parameters is: 12299542\n",
      "total number of parameters is: 12299542\n",
      "total number of parameters is: 12299542\n",
      "INFO:tensorflow:Create InsideHook.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create InsideHook.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create InsideHook.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create InsideHook.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "Before starting the session.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from estimator_zh_small/model.ckpt-10000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into estimator_zh_small/model.ckpt.\n",
      "INFO:tensorflow:Initialize strategy\n",
      "Session created.\n",
      "INFO:tensorflow:loss = 9.537512, step = 10000\n",
      "INFO:tensorflow:global_step/sec: 2.07626\n",
      "INFO:tensorflow:loss = 9.521952, step = 11000 (481.608 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11191 into estimator_zh_small/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.1809\n",
      "INFO:tensorflow:loss = 9.324627, step = 12000 (458.525 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12502 into estimator_zh_small/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.17421\n",
      "INFO:tensorflow:loss = 9.468273, step = 13000 (459.936 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13814 into estimator_zh_small/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.18106\n",
      "INFO:tensorflow:loss = 9.397345, step = 14000 (458.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.20946\n",
      "INFO:tensorflow:loss = 9.107819, step = 15000 (452.598 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15127 into estimator_zh_small/model.ckpt.\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(\n",
    "    lm_model_fn, train_input_fn, eval_input_fn, train_dir, params, eval_every=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
